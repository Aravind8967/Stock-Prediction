{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from src import CompanyDetails, FindValues, Analyse,PredictValues, SharePricePrediction\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import LSTM, Dense, Input, Dropout\n",
    "from keras.regularizers import l2\n",
    "kernel_regularizer=l2(0.01)\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BAJFINANCE added to list_of_df\n",
      "MARUTI added to list_of_df\n",
      "[              Close       ema100       ema200\n",
      "Date                                         \n",
      "2023-03-28  5483.50  5483.500000  5483.500000\n",
      "2023-03-29  5573.42  5485.280594  5484.394726\n",
      "2023-03-31  5565.05  5486.860186  5485.197266\n",
      "2023-04-03  5662.44  5490.337014  5486.960876\n",
      "2023-04-05  5708.27  5494.652519  5489.162957\n",
      "...             ...          ...          ...\n",
      "2025-03-24  9090.05  7812.052926  7473.221845\n",
      "2025-03-25  9067.25  7836.908313  7489.082822\n",
      "2025-03-26  8866.05  7857.287357  7502.783988\n",
      "2025-03-27  9003.85  7879.991567  7517.719968\n",
      "2025-03-28  8945.60  7901.092724  7531.927730\n",
      "\n",
      "[494 rows x 3 columns],                Close        ema100        ema200\n",
      "Date                                            \n",
      "2023-03-28   8056.18   8056.180000   8056.180000\n",
      "2023-03-29   8141.07   8057.860990   8057.024677\n",
      "2023-03-31   8137.98   8059.447505   8057.830202\n",
      "2023-04-03   8344.96   8065.101218   8060.687215\n",
      "2023-04-05   8290.00   8069.554659   8062.968934\n",
      "...              ...           ...           ...\n",
      "2025-03-24  11922.25  11933.066801  11828.420649\n",
      "2025-03-25  11868.90  11931.796172  11828.823429\n",
      "2025-03-26  11734.30  11927.885356  11827.882897\n",
      "2025-03-27  11721.95  11923.807428  11826.828839\n",
      "2025-03-28  11522.15  11915.853816  11823.797208\n",
      "\n",
      "[494 rows x 3 columns]]\n"
     ]
    }
   ],
   "source": [
    "c_list = ['BAJFINANCE','MARUTI']\n",
    "list_of_df = []\n",
    "windowsize = 5\n",
    "for c in c_list:\n",
    "    company_details = CompanyDetails(c)\n",
    "    share_price_df = company_details.sharePriceRange(period='2y')\n",
    "    share_price_df['Date'] = share_price_df['Date'].apply(lambda d: datetime.datetime.strptime(d, '%Y-%m-%d')).sort_index()\n",
    "    share_price_df.index = share_price_df.pop('Date')\n",
    "    list_of_df.append(share_price_df)\n",
    "    print(f'{c} added to list_of_df')\n",
    "\n",
    "print(list_of_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_windows_for_company(df, window_size=5):\n",
    "    \"\"\"\n",
    "    Given a DataFrame with columns ['Close', 'EMA200'],\n",
    "    create input windows (X) and corresponding target values (y).\n",
    "    \n",
    "    X shape => (num_samples, window_size, 2)  # 2 features: Close & EMA200\n",
    "    y shape => (num_samples,)                # Predict next day's Close\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    \n",
    "    # Sort by date if not already\n",
    "    df = df.sort_index()  # assumes date is the index\n",
    "    close_vals = df['Close'].values\n",
    "    ema_vals   = df['ema200'].values\n",
    "    \n",
    "    for i in range(len(df) - window_size):\n",
    "        # Window from i to i+window_size-1\n",
    "        X_window = []\n",
    "        for j in range(window_size):\n",
    "            X_window.append([close_vals[i+j], ema_vals[i+j]])\n",
    "        \n",
    "        # Target is the Close at i+window_size\n",
    "        target = close_vals[i + window_size]\n",
    "        \n",
    "        X.append(X_window)\n",
    "        y.append(target)\n",
    "    \n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_combine_data(list_of_dataframes, window_size=5):\n",
    "    \"\"\"\n",
    "    Accepts multiple DataFrames (one per company).\n",
    "    Returns combined X, y for training the model on all companies' data.\n",
    "    \"\"\"\n",
    "    X_combined, y_combined = [], []\n",
    "    \n",
    "    for df in list_of_dataframes:\n",
    "        X, y = create_windows_for_company(df, window_size)\n",
    "        if len(X) > 0:\n",
    "            X_combined.append(X)\n",
    "            y_combined.append(y)\n",
    "    \n",
    "    # Concatenate all arrays\n",
    "    if len(X_combined) == 0:\n",
    "        raise ValueError(\"No data found after window creation.\")\n",
    "    \n",
    "    X_all = np.concatenate(X_combined, axis=0)\n",
    "    y_all = np.concatenate(y_combined, axis=0)\n",
    "    return X_all, y_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub_x_train, pub_y_train = None, None\n",
    "pub_x_valid, pub_y_valid = None, None\n",
    "pub_x_test, pub_y_test = None, None\n",
    "\n",
    "\n",
    "def train_model(x_data, y_data):\n",
    "    \"\"\"\n",
    "    Build, compile, and train an LSTM model on the combined dataset.\n",
    "    Returns the trained model.\n",
    "    \"\"\"\n",
    "    # Split into train (80%), val (10%), test (10%) - or any ratio you prefer\n",
    "    num_samples = len(x_data)\n",
    "    train_end = int(num_samples * 0.8)\n",
    "    val_end   = int(num_samples * 0.9)\n",
    "    \n",
    "    x_train, y_train = x_data[:train_end], y_data[:train_end]\n",
    "    x_val,   y_val   = x_data[train_end:val_end], y_data[train_end:val_end]\n",
    "    x_test,  y_test  = x_data[val_end:], y_data[val_end:]\n",
    "\n",
    "    pub_x_train, pub_y_train = x_train, y_train\n",
    "    pub_x_valid, pub_y_valid = x_val, y_val\n",
    "    pub_x_test, pub_y_test = x_test, y_test\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(LSTM(units=120, activation='relu', return_sequences=True, input_shape=(x_data.shape[1], x_data.shape[2]), kernel_regularizer=l2(0.01), recurrent_dropout=0.2))\n",
    "\n",
    "    model.add(LSTM(units=64, activation='relu', return_sequences=True, kernel_regularizer=l2(0.01), recurrent_dropout=0.2))\n",
    "\n",
    "    model.add(LSTM(units=32, activation='relu', return_sequences=False, kernel_regularizer=l2(0.01), recurrent_dropout=0.2))\n",
    "    \n",
    "    model.add(Dense(32, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(16, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # final output layer\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "\n",
    "    model.compile(\n",
    "        loss='mse',\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        metrics=['mae']\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        x_train, y_train,\n",
    "        validation_data=(x_val, y_val),\n",
    "        epochs=10,\n",
    "        batch_size=32\n",
    "    )\n",
    "\n",
    "    test_loss, test_mae = model.evaluate(x_test, y_test)\n",
    "    print(f\"Test MSE: {test_loss:.4f}, Test MAE: {test_mae:.4f}\")\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(978, 5, 2)\n",
      "(978,)\n"
     ]
    }
   ],
   "source": [
    "x_all, y_all = load_and_combine_data(list_of_df, window_size=windowsize)\n",
    "\n",
    "print(x_all.shape)\n",
    "print(y_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aravind\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 73076280.0000 - mae: 8356.3564 - val_loss: 135803408.0000 - val_mae: 11646.3750\n",
      "Epoch 2/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 57026992.0000 - mae: 7321.2661 - val_loss: 28934580.0000 - val_mae: 4972.1494\n",
      "Epoch 3/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 18150200.0000 - mae: 3567.4089 - val_loss: 5998383.0000 - val_mae: 2121.6860\n",
      "Epoch 4/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 10781783.0000 - mae: 2571.3611 - val_loss: 281812.7812 - val_mae: 424.3774\n",
      "Epoch 5/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 9407202.0000 - mae: 2422.8523 - val_loss: 2624779.2500 - val_mae: 1570.3090\n",
      "Epoch 6/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 8256580.0000 - mae: 2272.3225 - val_loss: 774169.0625 - val_mae: 833.8271\n",
      "Epoch 7/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 7254801.0000 - mae: 2166.1687 - val_loss: 5476708.0000 - val_mae: 2314.5232\n",
      "Epoch 8/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8020393.5000 - mae: 2214.6968 - val_loss: 2397530.5000 - val_mae: 1469.6744\n",
      "Epoch 9/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 6654303.5000 - mae: 2057.4348 - val_loss: 2554448.2500 - val_mae: 1506.9734\n",
      "Epoch 10/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 6326132.5000 - mae: 1998.0256 - val_loss: 171722.0781 - val_mae: 311.3666\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 178606.1250 - mae: 361.4748\n",
      "Test MSE: 177006.2812, Test MAE: 354.4602\n"
     ]
    }
   ],
   "source": [
    "model = train_model(x_all, y_all)\n",
    "model.save(\"model_2.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Sequential name=sequential, built=True>\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
